{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.callbacks import History,LearningRateScheduler\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# print('TensorFlow %s, Keras %s, numpy %s, pandas %s'%(tf.__version__,keras.__version__, np.__version__,pd.__version__))\n",
    "__DEBUG__=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_concatener.csv', sep=';')\n",
    "test  = pd.read_csv('test_set_values.csv')\n",
    "full_data = [train, test]\n",
    "finalfile_index=test.id #Index des données de test pour le résultat final\n",
    "\n",
    "# Useless column\n",
    "train.drop('num_private', axis=1, inplace=True)\n",
    "train.drop('date_recorded', axis=1, inplace=True)\n",
    "train.drop('funder', axis=1, inplace=True)\n",
    "train.drop('installer', axis=1, inplace=True)\n",
    "train.drop('scheme_name', axis=1, inplace=True)\n",
    "train.drop('scheme_management', axis=1, inplace=True)\n",
    "train.drop('recorded_by', axis=1, inplace=True)\n",
    "train.drop('wpt_name', axis=1, inplace=True)\n",
    "train.drop('subvillage', axis=1, inplace=True)\n",
    "test.drop('num_private', axis=1, inplace=True)\n",
    "test.drop('date_recorded', axis=1, inplace=True)\n",
    "test.drop('funder', axis=1, inplace=True)\n",
    "test.drop('installer', axis=1, inplace=True)\n",
    "test.drop('scheme_name', axis=1, inplace=True)\n",
    "test.drop('scheme_management', axis=1, inplace=True)\n",
    "test.drop('recorded_by', axis=1, inplace=True)\n",
    "test.drop('subvillage', axis=1, inplace=True)\n",
    "test.drop('wpt_name', axis=1, inplace=True)\n",
    "\n",
    "# Double column\n",
    "train.drop('quantity', axis=1, inplace=True)\n",
    "train.drop('source', axis=1, inplace=True)\n",
    "train.drop('waterpoint_type', axis=1, inplace=True)\n",
    "train.drop('payment', axis=1, inplace=True)\n",
    "train.drop('management', axis=1, inplace=True)\n",
    "train.drop('extraction_type', axis=1, inplace=True)\n",
    "train.drop('extraction_type_group', axis=1, inplace=True)\n",
    "train.drop('water_quality', axis=1, inplace=True)\n",
    "train.drop('source_type', axis=1, inplace=True)\n",
    "train.drop('ward', axis=1, inplace=True)\n",
    "train.drop('lga', axis=1, inplace=True)\n",
    "train.drop('region', axis=1, inplace=True)\n",
    "train.drop('basin', axis=1, inplace=True)\n",
    "train.drop('longitude', axis=1, inplace=True)\n",
    "train.drop('latitude', axis=1, inplace=True)\n",
    "test.drop('quantity', axis=1, inplace=True)\n",
    "test.drop('source', axis=1, inplace=True)\n",
    "test.drop('waterpoint_type', axis=1, inplace=True)\n",
    "test.drop('payment', axis=1, inplace=True)\n",
    "test.drop('management', axis=1, inplace=True)\n",
    "test.drop('extraction_type', axis=1, inplace=True)\n",
    "test.drop('extraction_type_group', axis=1, inplace=True)\n",
    "test.drop('water_quality', axis=1, inplace=True)\n",
    "test.drop('source_type', axis=1, inplace=True)\n",
    "test.drop('ward', axis=1, inplace=True)\n",
    "test.drop('lga', axis=1, inplace=True)\n",
    "test.drop('region', axis=1, inplace=True)\n",
    "test.drop('basin', axis=1, inplace=True)\n",
    "test.drop('longitude', axis=1, inplace=True)\n",
    "test.drop('latitude', axis=1, inplace=True)\n",
    "\n",
    "# Refactoring value empty\n",
    "for dataset in full_data:\n",
    "    dataset.loc[dataset.public_meeting.isnull(), 'public_meeting'] = 0\n",
    "    dataset.loc[dataset.public_meeting == False, 'public_meeting'] = 0\n",
    "    dataset.loc[dataset.public_meeting == True, 'public_meeting'] = 1\n",
    "    # dataset.loc[dataset.latitude == 0.0, 'latitude'] = 35.225766\n",
    "    # dataset.loc[dataset.longitude == '-2,00E-08', 'longitude'] = -6.145943\n",
    "    dataset.loc[dataset.extraction_type_class == 'gravity', 'extraction_type_class'] = 0\n",
    "    dataset.loc[dataset.extraction_type_class == 'submersible', 'extraction_type_class'] = 1\n",
    "    dataset.loc[dataset.extraction_type_class == 'handpump', 'extraction_type_class'] = 2\n",
    "    dataset.loc[dataset.extraction_type_class == 'other', 'extraction_type_class'] = 3\n",
    "    dataset.loc[dataset.extraction_type_class == 'motorpump', 'extraction_type_class'] = 4\n",
    "    dataset.loc[dataset.extraction_type_class == 'wind-powered', 'extraction_type_class'] = 5\n",
    "    dataset.loc[dataset.extraction_type_class == 'rope pump', 'extraction_type_class'] = 6\n",
    "    dataset.loc[dataset.management_group == 'user-group', 'management_group'] = 0\n",
    "    dataset.loc[dataset.management_group == 'unknown', 'management_group'] = 1\n",
    "    dataset.loc[dataset.management_group == 'other', 'management_group'] = 1\n",
    "    dataset.loc[dataset.management_group == 'commercial', 'management_group'] = 2\n",
    "    dataset.loc[dataset.management_group == 'parastatal', 'management_group'] = 3\n",
    "    dataset.loc[dataset.payment_type == 'annually', 'payment_type'] = 0\n",
    "    dataset.loc[dataset.payment_type == 'never pay', 'payment_type'] = 1\n",
    "    dataset.loc[dataset.payment_type == 'per bucket', 'payment_type'] = 2\n",
    "    dataset.loc[dataset.payment_type == 'unknown', 'payment_type'] = 3\n",
    "    dataset.loc[dataset.payment_type == 'other', 'payment_type'] = 3\n",
    "    dataset.loc[dataset.payment_type == 'on failure', 'payment_type'] = 4\n",
    "    dataset.loc[dataset.payment_type == 'never pay', 'payment_type'] = 5\n",
    "    dataset.loc[dataset.payment_type == 'monthly', 'payment_type'] = 6\n",
    "    dataset.loc[dataset.quality_group == 'good', 'quality_group'] = 0\n",
    "    dataset.loc[dataset.quality_group == 'salty', 'quality_group'] = 1\n",
    "    dataset.loc[dataset.quality_group == 'milky', 'quality_group'] = 2\n",
    "    dataset.loc[dataset.quality_group == 'fluoride', 'quality_group'] = 3\n",
    "    dataset.loc[dataset.quality_group == 'colored', 'quality_group'] = 4\n",
    "    dataset.loc[dataset.quality_group == 'unknown', 'quality_group'] = 5\n",
    "    dataset.loc[dataset.quantity_group == 'enough', 'quantity_group'] = 0\n",
    "    dataset.loc[dataset.quantity_group == 'insufficient', 'quantity_group'] = 1\n",
    "    dataset.loc[dataset.quantity_group == 'dry', 'quantity_group'] = 2\n",
    "    dataset.loc[dataset.quantity_group == 'seasonal', 'quantity_group'] = 3\n",
    "    dataset.loc[dataset.quantity_group == 'unknown', 'quantity_group'] = 4\n",
    "    dataset.loc[dataset.source_class == 'groundwater', 'source_class'] = 0\n",
    "    dataset.loc[dataset.source_class == 'surface', 'source_class'] = 1\n",
    "    dataset.loc[dataset.source_class == 'unknown', 'source_class'] = 2\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'communal standpipe', 'waterpoint_type_group'] = 0\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'hand pump', 'waterpoint_type_group'] = 1\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'other', 'waterpoint_type_group'] = 2\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'improved spring', 'waterpoint_type_group'] = 3\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'cattle trough', 'waterpoint_type_group'] = 4\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'dam', 'waterpoint_type_group'] = 5\n",
    "    dataset.loc[dataset.permit.isnull(), 'permit'] = 0\n",
    "    dataset.loc[dataset.permit == False, 'permit'] = 0\n",
    "    dataset.loc[dataset.permit == True, 'permit'] = 1\n",
    "    dataset.loc[dataset.construction_year == 0, 'construction_year'] = np.NaN\n",
    "    construction_year_avg = dataset['construction_year'].mean() # Calcul de la valeur moyenne\n",
    "    construction_year_std = dataset['construction_year'].std()  # Calcul de l'écart type\n",
    "    construction_year_null_count = dataset['construction_year'].isnull().sum() # nombre de valeur nulle\n",
    "    construction_year_null_random_list = np.random.randint(construction_year_avg - construction_year_std, construction_year_avg + construction_year_std, size=construction_year_null_count)   \n",
    "    dataset.loc[np.isnan(dataset['construction_year']),'construction_year'] = construction_year_null_random_list    \n",
    "    dataset['construction_year'] = dataset['construction_year'].astype(int)\n",
    "    \n",
    "    dataset.loc[dataset.population == 0, 'population'] = np.NaN\n",
    "    population_avg = dataset['population'].mean() # Calcul de la valeur moyenne\n",
    "    population_std = dataset['population'].std()  # Calcul de l'écart type\n",
    "    population_null_count = dataset['population'].isnull().sum() # nombre de valeur nulle\n",
    "    population_null_random_list = np.random.randint(population_avg, population_avg + population_std, size=population_null_count)   \n",
    "    dataset.loc[np.isnan(dataset['population']),'population'] = population_null_random_list    \n",
    "    dataset['population'] = dataset['population'].astype(int)\n",
    "    # dataset.loc[dataset.management_group == 'unknown', 'management_group'] = 'other'\n",
    "    # dataset.loc[dataset.payment_type == 'unknown', 'payment_type'] = 'other'\n",
    "\n",
    "\n",
    "train['functional']= (train['status_group']=='functional')*1\n",
    "train['non_functional']= (train['status_group']=='non functional')*1\n",
    "train['functional_needs_repair']= (train['status_group']=='functional needs repair')*1\n",
    "\n",
    "train.drop('status_group', axis=1, inplace=True)\n",
    "\n",
    "BASE_DIR = os.path.abspath('')\n",
    "# print(BASE_DIR)\n",
    "train.to_csv(os.path.join(BASE_DIR, 'version_final.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               functional\n",
      "quality_group            \n",
      "0                0.565941\n",
      "1                0.460828\n",
      "2                0.544776\n",
      "3                0.723502\n",
      "4                0.502041\n",
      "5                0.140725\n",
      "               non_functional\n",
      "quality_group                \n",
      "0                    0.357236\n",
      "1                    0.482002\n",
      "2                    0.437811\n",
      "3                    0.216590\n",
      "4                    0.387755\n",
      "5                    0.840618\n",
      "               functional_needs_repair\n",
      "quality_group                         \n",
      "0                             0.076823\n",
      "1                             0.057170\n",
      "2                             0.017413\n",
      "3                             0.059908\n",
      "4                             0.110204\n",
      "5                             0.018657\n",
      "------------------------------------------------\n",
      "                functional\n",
      "quantity_group            \n",
      "0                 0.652323\n",
      "1                 0.523234\n",
      "2                 0.025136\n",
      "3                 0.574074\n",
      "4                 0.269962\n",
      "                non_functional\n",
      "quantity_group                \n",
      "0                     0.275357\n",
      "1                     0.380924\n",
      "2                     0.968940\n",
      "3                     0.323210\n",
      "4                     0.712294\n",
      "                functional_needs_repair\n",
      "quantity_group                         \n",
      "0                              0.072320\n",
      "1                              0.095842\n",
      "2                              0.005924\n",
      "3                              0.102716\n",
      "4                              0.017744\n",
      "------------------------------------------------\n",
      "                       functional\n",
      "waterpoint_type_group            \n",
      "0                        0.576491\n",
      "1                        0.617852\n",
      "2                        0.131661\n",
      "3                        0.718112\n",
      "4                        0.724138\n",
      "5                        0.857143\n",
      "                       non_functional\n",
      "waterpoint_type_group                \n",
      "0                            0.339523\n",
      "1                            0.323307\n",
      "2                            0.822414\n",
      "3                            0.173469\n",
      "4                            0.258621\n",
      "5                            0.142857\n",
      "                       functional_needs_repair\n",
      "waterpoint_type_group                         \n",
      "0                                     0.083986\n",
      "1                                     0.058840\n",
      "2                                     0.045925\n",
      "3                                     0.108418\n",
      "4                                     0.017241\n",
      "5                                     0.000000\n",
      "------------------------------------------------\n",
      "                  functional\n",
      "management_group            \n",
      "0                   0.538236\n",
      "1                   0.500000\n",
      "2                   0.614349\n",
      "3                   0.576923\n",
      "                  non_functional\n",
      "management_group                \n",
      "0                       0.387350\n",
      "1                       0.444814\n",
      "2                       0.353491\n",
      "3                       0.303733\n",
      "                  functional_needs_repair\n",
      "management_group                         \n",
      "0                                0.074414\n",
      "1                                0.055186\n",
      "2                                0.032161\n",
      "3                                0.119344\n",
      "------------------------------------------------\n",
      "              functional\n",
      "payment_type            \n",
      "0               0.752334\n",
      "1               0.448911\n",
      "2               0.677796\n",
      "3               0.449354\n",
      "4               0.620593\n",
      "6               0.660482\n",
      "              non_functional\n",
      "payment_type                \n",
      "0                   0.179846\n",
      "1                   0.475856\n",
      "2                   0.276683\n",
      "3                   0.490935\n",
      "4                   0.308636\n",
      "6                   0.227831\n",
      "              functional_needs_repair\n",
      "payment_type                         \n",
      "0                            0.067820\n",
      "1                            0.075233\n",
      "2                            0.045520\n",
      "3                            0.059711\n",
      "4                            0.070772\n",
      "6                            0.111687\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (train[[\"quality_group\", \"functional\"]].groupby(['quality_group'], as_index=1).mean())\n",
    "print (train[[\"quality_group\", \"non_functional\"]].groupby(['quality_group'], as_index=1).mean())\n",
    "print (train[[\"quality_group\", \"functional_needs_repair\"]].groupby(['quality_group'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print (train[[\"quantity_group\", \"functional\"]].groupby(['quantity_group'], as_index=1).mean())\n",
    "print (train[[\"quantity_group\", \"non_functional\"]].groupby(['quantity_group'], as_index=1).mean())\n",
    "print (train[[\"quantity_group\", \"functional_needs_repair\"]].groupby(['quantity_group'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print (train[[\"waterpoint_type_group\", \"functional\"]].groupby(['waterpoint_type_group'], as_index=1).mean())\n",
    "print (train[[\"waterpoint_type_group\", \"non_functional\"]].groupby(['waterpoint_type_group'], as_index=1).mean())\n",
    "print (train[[\"waterpoint_type_group\", \"functional_needs_repair\"]].groupby(['waterpoint_type_group'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print (train[[\"management_group\", \"functional\"]].groupby(['management_group'], as_index=1).mean())\n",
    "print (train[[\"management_group\", \"non_functional\"]].groupby(['management_group'], as_index=1).mean())\n",
    "print (train[[\"management_group\", \"functional_needs_repair\"]].groupby(['management_group'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print (train[[\"payment_type\", \"functional\"]].groupby(['payment_type'], as_index=1).mean())\n",
    "print (train[[\"payment_type\", \"non_functional\"]].groupby(['payment_type'], as_index=1).mean())\n",
    "print (train[[\"payment_type\", \"functional_needs_repair\"]].groupby(['payment_type'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "# print (train[[\"region\", \"functional\"]].groupby(['region'], as_index=1).mean())\n",
    "# print (train[[\"region\", \"non_functional\"]].groupby(['region'], as_index=1).mean())\n",
    "# print (train[[\"region\", \"functional_needs_repair\"]].groupby(['region'], as_index=1).mean())\n",
    "\n",
    "\n",
    "# print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "# rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44550 X_train, 14850 X_test, 44550 y_train, 14850 y_test\n",
      "59400 X_alltrain, 59400 y_alltrain\n",
      "features: ['amount_tsh', 'gps_height', 'region_code', 'district_code', 'population', 'public_meeting', 'permit', 'construction_year', 'extraction_type_class', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_class']\n",
      "target: ['Fonctionnel', 'Non fonctionnel', 'Necessite réparation']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Séparation des valeurs de train et label (tous les exemples)\n",
    "X_alltrain = train.values[:, 1:]\n",
    "y_alltrain = train.values[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_alltrain, y_alltrain, random_state=42)\n",
    "print('%i X_train, %i X_test, %i y_train, %i y_test'%(\n",
    "    X_train.shape[0], X_test.shape[0], y_train.shape[0], y_test.shape[0]))\n",
    "print('%i X_alltrain, %i y_alltrain'%(X_alltrain.shape[0], y_alltrain.shape[0]))\n",
    "feature_names=train.columns.tolist()[1:-4]\n",
    "target_names=[\"Fonctionnel\",\"Non fonctionnel\",\"Necessite réparation\"]\n",
    "print('features:',feature_names)\n",
    "print('target:',target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "def plot_decision_boundary(clf,X,y, axes=[-0, 5, 0, 550], axis_name=['x1','x2'],alpha=0.5, contour=True):\n",
    "\"\"\"\n",
    "    \"\"\"\n",
    "    Fonction pour l'affichage 2 D des résultats   \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : Classifier à afficher\n",
    "    X : features de Données a afficher\n",
    "    y : labels de Données a afficher  \n",
    "    axes : : Tailles des axes (valeur min/max)\n",
    "    axis_name : Nom des axes sur le graphique\n",
    "    alpha : Transparence des points\n",
    "    contour : Afichage du contour\n",
    "    \"\"\"     \n",
    "    \"\"\"\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bo\",label=\"Disparu\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"ys\", label=\"Rescapé\",alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(axis_name[0], fontsize=18)\n",
    "    plt.ylabel(axis_name[1]+ \"  \",fontsize=18, rotation=0)    \n",
    "    plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file=\"train_tree.dot\",\n",
    "        feature_names=feature_names,\n",
    "        class_names=target_names,\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n",
    "\n",
    "os.system(\"dot -Tpng train_tree.dot -o train_tree.png\") \n",
    "Image(\"train_tree.png\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=14 does not match number of samples=59400",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f8671e74d6fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Source : http://www.philipkalinda.com/ds6.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnew_rf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnew_rf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_alltrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_rf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_alltrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_targets_status\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 333\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[1;32m--> 236\u001b[1;33m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"min_weight_fraction_leaf must in [0, 0.5]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=14 does not match number of samples=59400"
     ]
    }
   ],
   "source": [
    "# Algorithm à utiliser : XGBClassifier to Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Source : http://www.philipkalinda.com/ds6.html\n",
    "new_rf_model = RandomForestClassifier(random_state = 123, n_estimators = 100)\n",
    "new_rf_model.fit(X_alltrain, feature_names)\n",
    "predictions = new_rf_model.predict(X_alltrain)\n",
    "print(len(new_targets_status[feature_names==predictions])/len(feature_names))\n",
    "\n",
    "kf = KFold(X_alltrain.shape[0], n_folds=10,shuffle=True,random_state=123)\n",
    "cvs = cross_val_score(new_rf_model,X_alltrain, feature_names,cv=kf)\n",
    "\n",
    "def iterate_rf(iterations,X_train,Y_train,X_final):\n",
    "    kf = KFold(X_train.shape[0], n_folds=10,shuffle=True,random_state=123)\n",
    "    pred_df = pd.DataFrame()\n",
    "    accuracies = []\n",
    "    for i in range(iterations):\n",
    "        rf_model = RandomForestClassifier(n_estimators = 100)\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(X_train, Y_train, test_size=0.25, random_state=123)\n",
    "        rf_model.fit(xtrain,ytrain)\n",
    "        predictions = rf_model.predict(xtest)\n",
    "        acc = len(ytest[ytest==predictions])/len(ytest)\n",
    "        accuracies.append(acc)\n",
    "        final_predictions = rf_model.predict(X_final)\n",
    "        pred_df[i] = final_predictions\n",
    "    return pred_df, accuracies\n",
    "\n",
    "rf_df, rf_accuracies = iterate_rf(200,X_alltrain, feature_names,y_alltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
