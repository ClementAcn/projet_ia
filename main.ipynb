{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.callbacks import History,LearningRateScheduler\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# print('TensorFlow %s, Keras %s, numpy %s, pandas %s'%(tf.__version__,keras.__version__, np.__version__,pd.__version__))\n",
    "__DEBUG__=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_concatener.csv', sep=';')\n",
    "test  = pd.read_csv('test_set_values.csv')\n",
    "full_data = [train, test]\n",
    "finalfile_index=test.id #Index des données de test pour le résultat final\n",
    "\n",
    "# Useless column\n",
    "train.drop('num_private', axis=1, inplace=True)\n",
    "train.drop('date_recorded', axis=1, inplace=True)\n",
    "train.drop('funder', axis=1, inplace=True)\n",
    "train.drop('installer', axis=1, inplace=True)\n",
    "train.drop('scheme_name', axis=1, inplace=True)\n",
    "train.drop('scheme_management', axis=1, inplace=True)\n",
    "train.drop('recorded_by', axis=1, inplace=True)\n",
    "train.drop('wpt_name', axis=1, inplace=True)\n",
    "train.drop('subvillage', axis=1, inplace=True)\n",
    "test.drop('num_private', axis=1, inplace=True)\n",
    "test.drop('date_recorded', axis=1, inplace=True)\n",
    "test.drop('funder', axis=1, inplace=True)\n",
    "test.drop('installer', axis=1, inplace=True)\n",
    "test.drop('scheme_name', axis=1, inplace=True)\n",
    "test.drop('scheme_management', axis=1, inplace=True)\n",
    "test.drop('recorded_by', axis=1, inplace=True)\n",
    "test.drop('subvillage', axis=1, inplace=True)\n",
    "test.drop('wpt_name', axis=1, inplace=True)\n",
    "\n",
    "# Double column\n",
    "train.drop('quantity', axis=1, inplace=True)\n",
    "train.drop('source', axis=1, inplace=True)\n",
    "train.drop('waterpoint_type', axis=1, inplace=True)\n",
    "train.drop('payment', axis=1, inplace=True)\n",
    "train.drop('management', axis=1, inplace=True)\n",
    "train.drop('extraction_type', axis=1, inplace=True)\n",
    "train.drop('extraction_type_group', axis=1, inplace=True)\n",
    "train.drop('water_quality', axis=1, inplace=True)\n",
    "train.drop('source_type', axis=1, inplace=True)\n",
    "train.drop('ward', axis=1, inplace=True)\n",
    "train.drop('lga', axis=1, inplace=True)\n",
    "train.drop('region', axis=1, inplace=True)\n",
    "train.drop('basin', axis=1, inplace=True)\n",
    "test.drop('quantity', axis=1, inplace=True)\n",
    "test.drop('source', axis=1, inplace=True)\n",
    "test.drop('waterpoint_type', axis=1, inplace=True)\n",
    "test.drop('payment', axis=1, inplace=True)\n",
    "test.drop('management', axis=1, inplace=True)\n",
    "test.drop('extraction_type', axis=1, inplace=True)\n",
    "test.drop('extraction_type_group', axis=1, inplace=True)\n",
    "test.drop('water_quality', axis=1, inplace=True)\n",
    "test.drop('source_type', axis=1, inplace=True)\n",
    "test.drop('ward', axis=1, inplace=True)\n",
    "test.drop('lga', axis=1, inplace=True)\n",
    "test.drop('region', axis=1, inplace=True)\n",
    "test.drop('basin', axis=1, inplace=True)\n",
    "\n",
    "# Refactoring value empty\n",
    "for dataset in full_data:\n",
    "    dataset.loc[dataset.public_meeting.isnull(), 'public_meeting'] = 0\n",
    "    dataset.loc[dataset.public_meeting == False, 'public_meeting'] = 0\n",
    "    dataset.loc[dataset.public_meeting == True, 'public_meeting'] = 1\n",
    "    dataset.loc[dataset.extraction_type_class == 'gravity', 'extraction_type_class'] = 0\n",
    "    dataset.loc[dataset.extraction_type_class == 'submersible', 'extraction_type_class'] = 1\n",
    "    dataset.loc[dataset.extraction_type_class == 'handpump', 'extraction_type_class'] = 2\n",
    "    dataset.loc[dataset.extraction_type_class == 'other', 'extraction_type_class'] = 3\n",
    "    dataset.loc[dataset.extraction_type_class == 'motorpump', 'extraction_type_class'] = 4\n",
    "    dataset.loc[dataset.extraction_type_class == 'wind-powered', 'extraction_type_class'] = 5\n",
    "    dataset.loc[dataset.extraction_type_class == 'rope pump', 'extraction_type_class'] = 6\n",
    "    dataset.loc[dataset.management_group == 'user-group', 'management_group'] = 0\n",
    "    dataset.loc[dataset.management_group == 'unknown', 'management_group'] = 1\n",
    "    dataset.loc[dataset.management_group == 'other', 'management_group'] = 1\n",
    "    dataset.loc[dataset.management_group == 'commercial', 'management_group'] = 2\n",
    "    dataset.loc[dataset.management_group == 'parastatal', 'management_group'] = 3\n",
    "    dataset.loc[dataset.payment_type == 'annually', 'payment_type'] = 0\n",
    "    dataset.loc[dataset.payment_type == 'never pay', 'payment_type'] = 1\n",
    "    dataset.loc[dataset.payment_type == 'per bucket', 'payment_type'] = 2\n",
    "    dataset.loc[dataset.payment_type == 'unknown', 'payment_type'] = 3\n",
    "    dataset.loc[dataset.payment_type == 'other', 'payment_type'] = 3\n",
    "    dataset.loc[dataset.payment_type == 'on failure', 'payment_type'] = 4\n",
    "    dataset.loc[dataset.payment_type == 'never pay', 'payment_type'] = 5\n",
    "    dataset.loc[dataset.payment_type == 'monthly', 'payment_type'] = 6\n",
    "    dataset.loc[dataset.quality_group == 'good', 'quality_group'] = 0\n",
    "    dataset.loc[dataset.quality_group == 'salty', 'quality_group'] = 1\n",
    "    dataset.loc[dataset.quality_group == 'milky', 'quality_group'] = 2\n",
    "    dataset.loc[dataset.quality_group == 'fluoride', 'quality_group'] = 3\n",
    "    dataset.loc[dataset.quality_group == 'colored', 'quality_group'] = 4\n",
    "    dataset.loc[dataset.quality_group == 'unknown', 'quality_group'] = 5\n",
    "    dataset.loc[dataset.quantity_group == 'enough', 'quantity_group'] = 0\n",
    "    dataset.loc[dataset.quantity_group == 'insufficient', 'quantity_group'] = 1\n",
    "    dataset.loc[dataset.quantity_group == 'dry', 'quantity_group'] = 2\n",
    "    dataset.loc[dataset.quantity_group == 'seasonal', 'quantity_group'] = 3\n",
    "    dataset.loc[dataset.quantity_group == 'unknown', 'quantity_group'] = 4\n",
    "    dataset.loc[dataset.source_class == 'groundwater', 'source_class'] = 0\n",
    "    dataset.loc[dataset.source_class == 'surface', 'source_class'] = 1\n",
    "    dataset.loc[dataset.source_class == 'unknown', 'source_class'] = 2\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'communal standpipe', 'waterpoint_type_group'] = 0\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'hand pump', 'waterpoint_type_group'] = 1\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'other', 'waterpoint_type_group'] = 2\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'improved spring', 'waterpoint_type_group'] = 3\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'cattle trough', 'waterpoint_type_group'] = 4\n",
    "    dataset.loc[dataset.waterpoint_type_group == 'dam', 'waterpoint_type_group'] = 5\n",
    "    dataset.loc[dataset.permit.isnull(), 'permit'] = 0\n",
    "    dataset.loc[dataset.permit == False, 'permit'] = 0\n",
    "    dataset.loc[dataset.permit == True, 'permit'] = 1\n",
    "    dataset.loc[dataset.construction_year == 0, 'construction_year'] = np.NaN\n",
    "    construction_year_avg = dataset['construction_year'].mean() # Calcul de la valeur moyenne\n",
    "    construction_year_std = dataset['construction_year'].std()  # Calcul de l'écart type\n",
    "    construction_year_null_count = dataset['construction_year'].isnull().sum() # nombre de valeur nulle\n",
    "    construction_year_null_random_list = np.random.randint(construction_year_avg - construction_year_std, construction_year_avg + construction_year_std, size=construction_year_null_count)   \n",
    "    dataset.loc[np.isnan(dataset['construction_year']),'construction_year'] = construction_year_null_random_list    \n",
    "    dataset['construction_year'] = dataset['construction_year'].astype(int)\n",
    "    # dataset.loc[dataset.management_group == 'unknown', 'management_group'] = 'other'\n",
    "    # dataset.loc[dataset.payment_type == 'unknown', 'payment_type'] = 'other'\n",
    "\n",
    "\n",
    "train['functional']= (train['status_group']=='functional')*1\n",
    "train['non_functional']= (train['status_group']=='non functional')*1\n",
    "train['functional_needs_repair']= (train['status_group']=='functional needs repair')*1\n",
    "\n",
    "train.drop('status_group', axis=1, inplace=True)\n",
    "\n",
    "BASE_DIR = os.path.abspath('')\n",
    "# print(BASE_DIR)\n",
    "train.to_csv(os.path.join(BASE_DIR, 'version_final.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               functional\n",
      "quality_group            \n",
      "0                0.565941\n",
      "1                0.460828\n",
      "2                0.544776\n",
      "3                0.723502\n",
      "4                0.502041\n",
      "5                0.140725\n",
      "               non_functional\n",
      "quality_group                \n",
      "0                    0.357236\n",
      "1                    0.482002\n",
      "2                    0.437811\n",
      "3                    0.216590\n",
      "4                    0.387755\n",
      "5                    0.840618\n",
      "               functional_needs_repair\n",
      "quality_group                         \n",
      "0                             0.076823\n",
      "1                             0.057170\n",
      "2                             0.017413\n",
      "3                             0.059908\n",
      "4                             0.110204\n",
      "5                             0.018657\n",
      "------------------------------------------------\n",
      "                functional\n",
      "quantity_group            \n",
      "0                 0.652323\n",
      "1                 0.523234\n",
      "2                 0.025136\n",
      "3                 0.574074\n",
      "4                 0.269962\n",
      "                non_functional\n",
      "quantity_group                \n",
      "0                     0.275357\n",
      "1                     0.380924\n",
      "2                     0.968940\n",
      "3                     0.323210\n",
      "4                     0.712294\n",
      "                functional_needs_repair\n",
      "quantity_group                         \n",
      "0                              0.072320\n",
      "1                              0.095842\n",
      "2                              0.005924\n",
      "3                              0.102716\n",
      "4                              0.017744\n",
      "------------------------------------------------\n",
      "                       functional\n",
      "waterpoint_type_group            \n",
      "0                        0.576491\n",
      "1                        0.617852\n",
      "2                        0.131661\n",
      "3                        0.718112\n",
      "4                        0.724138\n",
      "5                        0.857143\n",
      "                       non_functional\n",
      "waterpoint_type_group                \n",
      "0                            0.339523\n",
      "1                            0.323307\n",
      "2                            0.822414\n",
      "3                            0.173469\n",
      "4                            0.258621\n",
      "5                            0.142857\n",
      "                       functional_needs_repair\n",
      "waterpoint_type_group                         \n",
      "0                                     0.083986\n",
      "1                                     0.058840\n",
      "2                                     0.045925\n",
      "3                                     0.108418\n",
      "4                                     0.017241\n",
      "5                                     0.000000\n",
      "------------------------------------------------\n",
      "                  functional\n",
      "management_group            \n",
      "0                   0.538236\n",
      "1                   0.500000\n",
      "2                   0.614349\n",
      "3                   0.576923\n",
      "                  non_functional\n",
      "management_group                \n",
      "0                       0.387350\n",
      "1                       0.444814\n",
      "2                       0.353491\n",
      "3                       0.303733\n",
      "                  functional_needs_repair\n",
      "management_group                         \n",
      "0                                0.074414\n",
      "1                                0.055186\n",
      "2                                0.032161\n",
      "3                                0.119344\n",
      "------------------------------------------------\n",
      "              functional\n",
      "payment_type            \n",
      "0               0.752334\n",
      "1               0.448911\n",
      "2               0.677796\n",
      "3               0.449354\n",
      "4               0.620593\n",
      "6               0.660482\n",
      "              non_functional\n",
      "payment_type                \n",
      "0                   0.179846\n",
      "1                   0.475856\n",
      "2                   0.276683\n",
      "3                   0.490935\n",
      "4                   0.308636\n",
      "6                   0.227831\n",
      "              functional_needs_repair\n",
      "payment_type                         \n",
      "0                            0.067820\n",
      "1                            0.075233\n",
      "2                            0.045520\n",
      "3                            0.059711\n",
      "4                            0.070772\n",
      "6                            0.111687\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (train[[\"quality_group\", \"functional\"]].groupby(['quality_group'], as_index=1).mean())\n",
    "print (train[[\"quality_group\", \"non_functional\"]].groupby(['quality_group'], as_index=1).mean())\n",
    "print (train[[\"quality_group\", \"functional_needs_repair\"]].groupby(['quality_group'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print (train[[\"quantity_group\", \"functional\"]].groupby(['quantity_group'], as_index=1).mean())\n",
    "print (train[[\"quantity_group\", \"non_functional\"]].groupby(['quantity_group'], as_index=1).mean())\n",
    "print (train[[\"quantity_group\", \"functional_needs_repair\"]].groupby(['quantity_group'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print (train[[\"waterpoint_type_group\", \"functional\"]].groupby(['waterpoint_type_group'], as_index=1).mean())\n",
    "print (train[[\"waterpoint_type_group\", \"non_functional\"]].groupby(['waterpoint_type_group'], as_index=1).mean())\n",
    "print (train[[\"waterpoint_type_group\", \"functional_needs_repair\"]].groupby(['waterpoint_type_group'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print (train[[\"management_group\", \"functional\"]].groupby(['management_group'], as_index=1).mean())\n",
    "print (train[[\"management_group\", \"non_functional\"]].groupby(['management_group'], as_index=1).mean())\n",
    "print (train[[\"management_group\", \"functional_needs_repair\"]].groupby(['management_group'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print (train[[\"payment_type\", \"functional\"]].groupby(['payment_type'], as_index=1).mean())\n",
    "print (train[[\"payment_type\", \"non_functional\"]].groupby(['payment_type'], as_index=1).mean())\n",
    "print (train[[\"payment_type\", \"functional_needs_repair\"]].groupby(['payment_type'], as_index=1).mean())\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "# print (train[[\"region\", \"functional\"]].groupby(['region'], as_index=1).mean())\n",
    "# print (train[[\"region\", \"non_functional\"]].groupby(['region'], as_index=1).mean())\n",
    "# print (train[[\"region\", \"functional_needs_repair\"]].groupby(['region'], as_index=1).mean())\n",
    "\n",
    "\n",
    "# print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)\n",
    "# rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44550 X_train, 14850 X_test, 44550 y_train, 14850 y_test\n",
      "59400 X_alltrain, 59400 y_alltrain\n",
      "features: ['amount_tsh', 'gps_height', 'region_code', 'district_code', 'population', 'public_meeting', 'permit', 'construction_year', 'extraction_type_class', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_class']\n",
      "target: ['Fonctionnel', 'Non fonctionnel', 'Necessite réparation']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Séparation des valeurs de train et label (tous les exemples)\n",
    "X_alltrain = train.values[:, 1:]\n",
    "y_alltrain = train.values[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_alltrain, y_alltrain, random_state=42)\n",
    "print('%i X_train, %i X_test, %i y_train, %i y_test'%(\n",
    "    X_train.shape[0], X_test.shape[0], y_train.shape[0], y_test.shape[0]))\n",
    "print('%i X_alltrain, %i y_alltrain'%(X_alltrain.shape[0], y_alltrain.shape[0]))\n",
    "feature_names=train.columns.tolist()[1:-4]\n",
    "target_names=[\"Fonctionnel\",\"Non fonctionnel\",\"Necessite réparation\"]\n",
    "print('features:',feature_names)\n",
    "print('target:',target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of feature_names, 14 does not match number of features, 18",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0bfd31e12c48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mclass_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mrounded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mfilled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[1;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[0;32m    425\u001b[0m                                  \u001b[1;34m\"does not match number of features, %d\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m                                  % (len(feature_names),\n\u001b[1;32m--> 427\u001b[1;33m                                     decision_tree.n_features_))\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;31m# The depth of each node for plotting with 'leaf' option\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of feature_names, 14 does not match number of features, 18"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "def plot_decision_boundary(clf,X,y, axes=[-0, 5, 0, 550], axis_name=['x1','x2'],alpha=0.5, contour=True):\n",
    "\"\"\"\n",
    "    \"\"\"\n",
    "    Fonction pour l'affichage 2 D des résultats   \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : Classifier à afficher\n",
    "    X : features de Données a afficher\n",
    "    y : labels de Données a afficher  \n",
    "    axes : : Tailles des axes (valeur min/max)\n",
    "    axis_name : Nom des axes sur le graphique\n",
    "    alpha : Transparence des points\n",
    "    contour : Afichage du contour\n",
    "    \"\"\"     \n",
    "    \"\"\"\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bo\",label=\"Disparu\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"ys\", label=\"Rescapé\",alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(axis_name[0], fontsize=18)\n",
    "    plt.ylabel(axis_name[1]+ \"  \",fontsize=18, rotation=0)    \n",
    "    plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file=\"train_tree.dot\",\n",
    "        feature_names=feature_names,\n",
    "        class_names=target_names,\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n",
    "\n",
    "os.system(\"dot -Tpng train_tree.dot -o train_tree.png\") \n",
    "Image(\"train_tree.png\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
